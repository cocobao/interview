

共享内存实现：

		就是分配一块能被其他进程访问的内存。共享内存可以说是最有用的进程间通信方式，也是最快的IPC形式。首先说下在使用共享内存
	区前，必须通过系统函数将其附加到进程的地址空间或说为映射到进程空间。两个不同进程A、B共享内存的意思是，同一块物理内存被映射
	到进程A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然
	需要某种同步机制，互斥锁和信号量都可以。采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任
	何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据[1]：一次
	从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的
	通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享
	内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。

ELF是什么？

		可执行连接格式，是UNIX系统实验室（USL）作为应用程序二进制接口（Application Binary Interface，ABI）而开发和发布的。扩
	展名为elf。工具接口标准委员会(TIS)选择了正在发展中的ELF标准作为工作在32位INTEL体系上不同操作系统之间可移植的二进制文件格
	式。假定开发者定义了一个二进制接口集合，ELF标准用它来支持流线型的软件发展。应该减少不同执行接口的数量。因此可以减少重新编程
	重新编译的代码。
	ELF文件（目标文件）格式主要三种:
	1）可重定向文件：文件保存着代码和适当的数据，用来和其他的目标文件一起来创建一个可执行文件或者是一个共享目标文件。（目标文件或者
	静态库文件，即linux通常后缀为.a和.o的文件）
	2）可执行文件：文件保存着一个用来执行的程序。（例如bash，gcc等）
	3）共享目标文件：共享库。文件保存着代码和合适的数据，用来被下连接编辑器和动态链接器链接。（linux下后缀为.so的文件。）
	
BSS段

		BSS（Block Started by Symbol）通常是指用来存放程序中未初始化的全局变量和静态变量的一块内存区域。特点是:可读写的，在
	程序执行之前BSS段会自动清0。所以，未初始的全局变量在程序执行之前已经成0了。
	注意和数据段的区别，BSS存放的是未初始化的全局变量和静态变量，数据段存放的是初始化后的全局变量和静态变量。
	
内存分布

	可执行二进制程序 = 代码段(text)＋数据段(data)+BSS段
	正在运行的C程序 = 代码段+初始化数据段(data)+未初始化数据段(BSS)+堆+栈
	
	
进程之间通讯方式

	进程间通信：
	管道、有名管道、消息队列、信号量、共享内存、信号、套接字。
	
	线程间通信：
	（1）原子操作符集
	（2）关键代码段（Windows）
	（3）互斥锁
	（4）信号量
	（5）条件变量（Linux）
	（6）读写锁（Linux）
	
如何定位内存泄露？

		内存泄漏是指堆内存的泄漏。堆内存是指程序从堆中分配的、大小任意的（内存块的大小可以在程序运行期决定）、使用完后必须显示释
	放的内存。应用程序一般使用malloc、realloc、new等函数从堆中分配到一块内存，使用完后，程序必须负责相应的调用free或delete
	释放该内存块。否则，这块内存就不能被再次使用，我们就说这块内存泄漏了。
		C++程序缺乏相应的手段来检测内存信息，只能使用top指令观察进程的动态内存总额。而且程序退出时，我们无法获知任何内存泄漏信息
	使用Linux命令回收内存，可以使用ps、kill两个命令检测内存使用情况和进行回收。在使用超级用户权限时使用命令“ps”，它会列出所有正在运行
	的程序名称和对应的进程号（PID）。kill命令的工作原理是向Linux操作系统的内核送出一个系统操作信号和程序的进程号（PID）

动态链接和静态链接的区别

	动态链接是指在生成可执行文件时不将所有程序用到的函数链接到一个文件，因为有许多函数在操作系统带的dll文件中，当程序运行时直接从操作系统中找。 而静态链接就是把所有用到的函数全部链接到exe文件中。
	动态链接是只建立一个引用的接口，而真正的代码和数据存放在另外的可执行模块中，在运行时再装入；而静态链接是把所有的代码和数据都复制到本模块中，运行时就不再需要库了。

c程序辨别系统是16位or32位
	法一：int k=~0;
	
	if((unsigned int)k >63356) cout<<"at least 32bits"<<endl;
	else cout<<"16 bits"<<endl;
	
	法二：//32为系统
	
	int i=65536;
	cout<<i<<endl;
	int j=65535;
	cout<<j<<endl;
	
大端or小端字节序

	1) Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。
	2) Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。
	举一个例子，比如数字0x12 34 56 78在内存中的表示形式为：
	
	1)大端模式：
	低地址 -----------------> 高地址
	0x12  |  0x34  |  0x56  |  0x78
	2)小端模式：
	低地址 ------------------> 高地址
	0x78  |  0x56  |  0x34  |  0x12
	
	32bit宽的数0x12345678在Little-endian模式以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为：
	内存地址	小端模式存放内容    大端模式存放内容
	0x4000		0x78		0x12
	0x4001		0x56		0x34
	0x4002		0x34		0x56
	0x4003		0x12		0x78
	
	4)大端小端没有谁优谁劣，各自优势便是对方劣势：
	小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。
	大端模式 ：符号位的判定固定为第一个字节，容易判断正负。


	BOOL IsBigEndian()  
	{  
	    int a = 0x1234;  
	    char b =  *(char *)&a;  //通过将int强制类型转换成char单字节，通过判断起始存储位置。即等于 取b等于a的低地址部分  
	    if( b == 0x12)  
	    {  
	        return TRUE;  
	    }  
	    return FALSE;  
	}

	联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写：

	BOOL IsBigEndian()  
	{  
	    union NUM  
	    {  
	        int a;  
	        char b;  
	    }num;  
	    num.a = 0x1234;  
	    if( num.b == 0x12 )  
	    {  
	        return TRUE;  
	    }  
	    return FALSE;  
	}

i++是否原子操作？并解释为什么
	
	i++分为三个阶段：
	内存到寄存器
	寄存器自增
	写回内存
	这三个阶段中间都可以被中断分离开.

linux系统的各类同步机制
	
	自旋锁,读写锁,原子操作,信号量,等待队列,

死锁必要条件及避免算法、

	1、互斥条件，资源不能共享，只能由一个进程使用。
	2、请求与保持条件（Hold andwait）：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
	3、不剥夺条件（Nopre-emption）：进程已获得的资源，在末使用完之前，不能强行剥夺。
	4、循环等待：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源

	处理死锁的策略：
	1.忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。
	2.检测死锁并且恢复。
	3.仔细地对资源进行动态分配，以避免死锁。
	4.通过破除死锁四个必要条件之一，来防止死锁产生。

exit()与_exit()的区别？

	_exit终止调用进程，但不关闭文件，不清除输出缓存，也不调用出口函数。
	exit函数将终止调用进程。在退出程序之前，所有文件关闭，缓冲输出内容将刷新定义，并调用所有已刷新的“出口函数”

linux的内存管理机制是什么？

		Linux虚拟内存的实现需要6种机制的支持：地址映射机制、内存分配回收机制、缓存和刷新机制、请求页机制、交换机制和内存共享机制
		内存管理程序通过映射机制把用户程序的逻辑地址映射到物理地址。当用户程序运行时，如果发现程序中要用的虚地址没有对应的物理内存，
	就发出了请求页要求。如果有空闲的内存可供分配，就请求分配内存(于是用到了内存的分配和回收)，并把正在使用的物理页记录在缓存中(使用了缓
	存机制)。如果没有足够的内存可供分配，那么就调用交换机制；腾出一部分内存。另外，在地址映射中要通过TLB(翻译后援存储器)来寻找物理页；
	交换机制中也要用到交换缓存，并且把物理页内容交换到交换文件中，也要修改页表来映射文件地址。

任务调度算法：

	1. 先来先服务
	2. 短作业优先算法
	3. 时间片轮转算法
	4. 优先级算法

五种I/O 模式—

	【1】阻塞I/O         (Linux下的I/O操作默认是阻塞I/O，即open和socket创建的I/O都是阻塞I/O)
	【2】非阻塞 I/O      (可以通过fcntl或者open时使用O_NONBLOCK参数，将fd设置为非阻塞的I/O)
	【3】I/O 多路复用    (I/O多路复用，通常需要非阻塞I/O配合使用)
	【4】信号驱动 I/O    (SIGIO)
	【5】异步 I/O

Apache 模型（Process Per Connection，简称PPC），TPC（ThreadPer Connection）模型，以及 select 模型和 poll 模型，epoll模型

	 PPC/TPC 模型
		这两种模型思想类似，就是让每一个到来的连接一边自己做事去，别再来烦我。只是 PPC 是为它开了一个进程，而 TPC 开了一个线程。
	可是别烦我是有代价的，它要时间和空间啊，连接多了之后，那么多的进程 / 线程切换，这开销就上来了；因此这类模型能接受的最大连接数都不
	会高，一般在几百个左右。

	select 模型
	1. 最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的，由FD_SETSIZE 设置，默认值是 1024/2048 ，因此 Select
	模型的最大并发数就被相应限制了。自己改改这个 FD_SETSIZE ？想法虽好，可是先看看下面吧 …
	2. 效率问题， select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来.
	3. 内核 / 用户空间内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法。

	poll 模型
	基本上效率和select 是相同的，select 缺点的 2 和 3 它都没有改掉。

	Epoll 的提升
	把其他模型逐个批判了一下，再来看看 Epoll 的改进之处吧，其实把 select 的缺点反过来那就是 Epoll 的优点了。
	3.1. Epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大，
	具体数目可以 cat /proc/sys/fs/file-max 察看。
	3.2. 效率提升， Epoll 最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中， Epoll 的效率就会远远
	高于 select 和 poll 。
	3.3. 内存拷贝， Epoll 在这点上使用了“共享内存 ”，这个内存拷贝也省略了。

select和epoll的区别
	
		select的本质是采用32个整数的32位，即32*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE
	的大小。这个时候就可以标识32*max值范围的fd。

	对于单进程多线程，每个线程处理多个fd的情况，select是不适合的。
	1.所有的线程均是从1-32*max进行扫描，每个线程处理的均是一段fd值，这样做有点浪费
	2.1024上限问题，一个处理多个用户的进程，fd值远远大于1024
	所以这个时候应该采用poll，
	
		poll传递的是数组头指针和该数组的长度，只要数组的长度不是很长，性能还是很不错的，因为poll一次在内核中申请4K（一个页的大小
	来存放fd），尽量控制在4K以内.
		epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用
	户态，然后传递到内核中。但是只有在2.6的内核才支持。
		epoll更适合于处理大量的fd ，且活跃fd不是很多的情况，毕竟fd较多还是一个串行的操作
	
	epoll哪些触发模式，有啥区别？（必须非常详尽的解释水平触发和边缘触发的区别，以及边缘触发在编程中要做哪些更多的确认）
		epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有
	采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。
		epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表
	就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉
	了这些文件描述符在系统调用时复制的开销。
		另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描
	述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速
	激活这个文件描述符，当进程调用epoll_wait()时便得到通知。	



一个String类的实现

	class String  
	{  
	public:  
		String(const char *str = NULL);// 普通构造函数    
		String(const String &other);// 拷贝构造函数    
		~String(void);// 析构函数    
		String & operator = (const String &other);// 赋值函数    
	private:  
		char *m_data;// 用于保存字符串    
	};  
	请编写String的上述4个函数。

	//普通构造函数    
	String::String(const char *str)  
	{  
		if (str == NULL)  
		{  
			m_data = new char[1];// 得分点：对空字符串自动申请存放结束标志'\0'的，加分点：对m_data加NULL判断    
			*m_data = '\0';  
		}  
		else  
		{  
			int length = strlen(str);  
			m_data = new char[length + 1];// 若能加 NULL 判断则更好    
			strcpy(m_data, str);  
		}  
	}  

	// String的析构函数    
	String::~String(void)  
	{  
		delete[] m_data; // 或delete m_data;    
	}  

	//拷贝构造函数    
	String::String(const String &other)// 得分点：输入参数为const型    
	{          
		int length = strlen(other.m_data);  
		m_data = new char[length + 1];//加分点：对m_data加NULL判断    
		strcpy(m_data, other.m_data);  
	}  

	//赋值函数    
	String & String::operator = (const String &other) // 得分点：输入参数为const型    
	{  
		if (this == &other)//得分点：检查自赋值    
			return *this;   
		if (m_data)  
			delete[] m_data;//得分点：释放原有的内存资源    
		int length = strlen(other.m_data);  
		m_data = new char[length + 1];//加分点：对m_data加NULL判断    
		strcpy(m_data, other.m_data);  
		return *this;//得分点：返回本对象的引用      
	}

 虚函数的作用和实现原理，什么是虚函数,有什么作用?

	C++的多态分为静态多态（编译时多态）和动态多态（运行时多态）两大类。
	静态多态通过重载、模板来实现；
	动态多态就是通过本文的主角虚函数来体现的。	
	
	虚函数实现原理:包括虚函数表、虚函数指针等 。
	如果是基类的实例，对应位置存放的是基类的函数指针；
	如果是继承类，对应位置存放的是继承类的函数指针（如果在继承类有实现）。
	所以 ，当使用基类指针调用对象方法时，也会根据具体的实例，调用到继承类的方法
	
	虚函数的作用：
		当调用一个虚函数时，被执行的代码必须和调用函数的对象的动态类型相一致。编译器需要做的就是如何高效的实现提供这种特性。
	不同编译器实现细节也不相同。大多数编译器通过vtbl（virtual table）和vptr（virtual table pointer）来实现的。
	当一个类声明了虚函数或者继承了虚函数，这个类就会有自己的vtbl。vtbl实际上就是一个函数指针数组，有的编译器用的是链表，
	不过方法都是差不多。vtbl数组中的每一个元素对应一个函数指针指向该类的一个虚函数，同时该类的每一个对象都会包含一个vptr，
	vptr指向该vtbl的地址。

	结论：
	每个声明了虚函数或者继承了虚函数的类，都会有一个自己的vtbl
	同时该类的每个对象都会包含一个vptr去指向该vtbl
	虚函数按照其声明顺序放于vtbl表中, vtbl数组中的每一个元素对应一个函数指针指向该类的虚函数
	如果子类覆盖了父类的虚函数，将被放到了虚表中原来父类虚函数的位置
	在多继承的情况下，每个父类都有自己的虚表。子类的成员函数被放到了第一个父类的表中

指针和引用的区别

	相同点：
	1. 都是地址的概念；
	指针指向一块内存，它的内容是所指内存的地址；引用是某块内存的别名。

	区别：
	1. 指针是一个实体，而引用仅是个别名；
	2. 引用使用时无需解引用(*)，指针需要解引用；
	3. 引用只能在定义时被初始化一次，之后不可变；指针可变；
	4. 引用没有 const，指针有 const；
	5. 引用不能为空，指针可以为空；
	6. “sizeof 引用”得到的是所指向的变量(对象)的大小，而“sizeof 指针”得到的是指针本身(所指向的变量或对象的地址)的大小；
	7. 指针和引用的自增(++)运算意义不一样；
	8. 从内存分配上看：程序为指针变量分配内存区域，而引用不需要分配内存区域。

多重类构造和析构的顺序

	先调用基类的构造函数，在调用派生类的构造函数
	先构造的后析构，后构造的先析构

STL各容器的实现原理
	
	STL共有六大组件:1、容器。2、算法。3、迭代器。4、仿函数。6、适配器。

	序列式容器：
	vector - 数组，元素不够时再重新分配内存，拷贝原来数组的元素到新分配的数组中。
	list － 单链表。
	deque - 分配中央控制器map(并非map容器)，map记录着一系列的固定长度的数组的地址.记住这个map仅仅保存的是数组的地址,
	真正的数据在数组中存放着.deque先从map中央的位置(因为双向队列，前后都可以插入元素)找到一个数组地址，向该数组中放入数据，
	数组不够时继续在map中找空闲的数组来存数据。当map也不够时重新分配内存当作新的map,把原来map中的内容copy的新map中。
	所以使用deque的复杂度要大于vector，尽量使用vector。
	stack-基于deque。
	queue-基于deque。
	heap-完全二叉树，使用最大堆排序，以数组(vector)的形式存放。
	priority_queue-基于heap。
	slist-双向链表。

	关联式容器：
	set,map,multiset,multimap-基于红黑树(RB-tree)，一种加上了额外平衡条件的二叉搜索树。
	
	hash table-散列表。将待存数据的key经过映射函数变成一个数组(一般是vector)的索引，例如：数据的key%数组的大小＝数组的索引
	(一般文本通过算法也可以转换为数字)，然后将数据当作此索引的数组元素。有些数据的key经过算法的转换可能是同一个数组的索引值
	(碰撞问题，可以用线性探测，二次探测来解决)，STL是用开链的方法来解决的，每一个数组的元素维护一个list，他把相同索引值的数据
	存入一个list，这样当list比较短时执行删除，插入，搜索等算法比较快。

	hash_map,hash_set,hash_multiset,hash_multimap-基于hashtable。

volatile作用

	volatile的本意是“易变的” 因为访问寄存器要比访问内存单元快的多,所以编译器一般都会作减少存取内存的优化，但有可能会读脏数据。
	当要求使用volatile声明变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。精确地说就是，
	遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用volatile，
	则编译器将对所声明的语句进行优化。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时
	可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错）

tcp与udp的区别

	1．基于连接与无连接 
	2．对系统资源的要求（TCP较多，UDP少） 
	3．UDP程序结构较简单 
	4．流模式与数据报模式
	5．TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证

	TCP---传输控制协议,提供的是面向连接、可靠的字节流服务。当客户和服务器彼此交换数据前，必须先在双方之间建立一个TCP连接，
	之后才能传输数据。TCP提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。
	UDP---用户数据报协议，是一个简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，
	但是并不能保证它们能到达目的地。由于UDP在传输数据报前不用在客户和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快

udp调用connect有什么作用？

	1:UDP中可以使用connect系统调用
	2:UDP中connect操作与TCP中connect操作有着本质区别.TCP中调用connect会引起三次握手,client与server建立连结.
	UDP中调用connect内核仅仅把对端ip&port记录下来.
	3:UDP中可以多次调用connect,TCP只能调用一次connect.
	UDP多次调用connect有两种用途:
	#1,指定一个新的ip&port连结.
	#2,断开和之前的ip&port的连结.指定新连结,直接设置connect第二个参数即可.断开连结,需要将connect第二个参数中的sin_family设置成 AF_UNSPEC即可. 
	4:UDP中使用connect可以提高效率.原因如下:
	普通的UDP发送两个报文内核做了如下:
	#1:建立连结
	#2:发送报文
	#3:断开连结
	#4:建立连结
	#5:发送报文
	#6:断开连结
	采用connect方式的UDP发送两个报文内核如下处理:
	#1:建立连结
	#2:发送报文
	#3:发送报文另外一点,每次发送报文内核都由可能要做路由查询.
	
	5:采用connect的UDP发送接受报文可以调用send,write和recv,read操作.当然也可以调用sendto,recvfrom.调用sendto的时候第五个参数必须是NULL,第六个参数是0.调用recvfrom,recv,read系统调用只能获取到先前connect的ip&port发送的报文. 
	
	UDP中使用connect的好处:
	1:会提升效率.前面已经描述了.
	2:高并发服务中会增加系统稳定性.
	原因:假设client A 通过非connect的UDP与serverB,C通信.B,C提供相同服务.为了负载均衡,我们让A与B,C交替通信.
	A 与 B通信IPa:PORTa<----> IPb:PORTbA 与 C通信IPa:PORTa'<---->IPc:PORTc 
	假设PORTa 与 PORTa'相同了(在大并发情况下会发生这种情况),那么就有可能出现A等待B的报文,却收到了C的报文.导致收报错误.
	解决方法内就是采用connect的UDP通信方式.在A中创建两个udp,然后分别connect到B,C.

大规模连接上来，并发模型怎么设计

	增加机群, Nginx负载均衡 + 自己设计的负载均衡策略

tcp三次握手：

	（1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，
	等待Server确认。
        （2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，
	随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。
        （3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，
	并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server
	进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

	SYN攻击：
                在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），
	此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在
	的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要
	不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统
	瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以
	断定遭到SYN攻击了，使用如下命令可以让之现行：
                #netstat -nap | grep SYN_RECV

tcp四次挥手：
	
	（1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。
       （2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），
       Server进入CLOSE_WAIT状态。
       （3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。
       （4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，
       Server进入CLOSED状态，完成四次挥手。

time_wait状态:

	TIME_WAIT：表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，
	最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是
	2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到
	CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须
	经过FIN_WAIT_2状态。
	
	time_wait状态产生的原因:
	1）为实现TCP全双工连接的可靠释放
	假设发起主动关闭的一方（client）最后发送的ACK在网络中丢失，由于TCP协议的重传机制，执行被动关闭的一方（server）
	将会重发其FIN，在该FIN到达client之前，client必须维护这条连接状态，也就说这条TCP连接所对应的资源（client方的
	local_ip,local_port）不能被立即释放或重新分配，直到另一方重发的FIN达到之后，client重发ACK后，经过2MSL时间
	周期没有再收到另一方的FIN之后，该TCP连接才能恢复初始的CLOSED状态。如果主动关闭一方不维护这样一个TIME_WAIT状态，
	那么当被动关闭一方重发的FIN到达时，主动关闭一方的TCP传输层会用RST包响应对方，这会被对方认为是有错误发生，然而这
	事实上只是正常的关闭连接过程，并非异常。
	2）为使旧的数据包在网络因过期而消失
	我们先假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,
	remote_port)，因某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。本文前面介绍过，TCP连接由四元组唯一
	标识，因此，在我们假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间
	先释放再建立的过程对其来说是“感知”不到的。这样就可能发生这样的情况：前一条TCP连接由local peer发送的数据到达
	remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假
	设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是
	不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。作为一种可靠的传输协议，TCP必须在协议
	层面考虑并避免这种情况的发生，这正是TIME_WAIT状态存在的第2个原因。
	
	具体而言，local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四
	元组建立新连接，即发起active close的那方占用的local port在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态
	持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立
	一条新连接而不会发生前后两次连接数据错乱的情况。
	
	time_wait状态如何避免
	首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口。
	在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR
	选项就可以避免TIME_WAIT状态。

什么是滑动窗口，超时重传，拥塞控制

	超时重传：
	在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的ACK报文，那么就重新发送数据，直到发送
	成功为止。
	影响超时重传机制协议效率的一个关键参数是重传超时时间（RTO，Retransmission TimeOut）。RTO的值被设置过大过小都
	会对协议造成不利影响。 
	（1）RTO设长了，重发就慢，没有效率，性能差。 
	（2）RTO设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

	滑动窗口：
	接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制。
	发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。 

	拥塞控制：
	TCP拥塞控制4个核心算法：慢开始（slow start）、拥塞避免（Congestion Avoidance）、快速重传（fast retransmit）
	、快速回复（fast recovery） 
	拥塞窗口（cwnd，congestion window），其大小取决于网络的拥塞程度，并且动态地在变化。 
	慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。
	拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送发的拥塞窗口cwnd加1，而不是加倍。
	快速重传(Fast retransmit)要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没
	有到达对方），而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到3个重复确认就应当立即重传对方尚未
	收到的报文段，而不必继续等待设置的重传计数器时间到期。
	快速恢复(Fast Recovery) 
	（1）当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。
	请注意：接下去不执行慢开始算法。 
	（2）由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在
	不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥
	塞窗口缓慢地线性增大。

keepalive是什么东东？如何使用

	设置Keepalive参数，检测已中断的客户连接
	在TCP中有一个Keep-alive的机制可以检测死连接，原理很简单，TCP会在空闲了一定时间后发送数据给对方：
	1.如果主机可达，对方就会响应ACK应答，就认为是存活的。
	2.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。
	3.如果可达，但应用程序崩溃，对方就发FIN消息。
	4.如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。这个时间就是默认的二个小时。

OFFSETOF(s, m)的宏定义，s是结构类型，m是s的成员，求m在s中的偏移量。

	#define OFFSETOF(s, m) ({s s1;(void*)(&s1)-(void*)(&s1->m);})/*gcc*/


100亿个数，求最大的1万个数，并说出算法的时间复杂度。
	
	建一个堆,先把最开始的1万个数放进去。以后每进一个，都把最小的赶出来。

